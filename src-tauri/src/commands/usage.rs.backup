use chrono::{DateTime, Local, NaiveDate, Duration};
use serde::{Deserialize, Serialize};
use serde_json;
use std::collections::{HashMap, HashSet};
use std::fs;
use std::path::PathBuf;
use std::env;
use std::sync::{Arc, Mutex};
use std::time::{SystemTime, UNIX_EPOCH};
use tauri::{command, AppHandle, Manager};

#[derive(Debug, Clone)]
struct UsageCacheEntry {
    data: UsageStats,
    timestamp: u64,
    file_hash: String,
}

// Global cache - thread-safe
lazy_static::lazy_static! {
    static ref USAGE_CACHE: Arc<Mutex<HashMap<String, UsageCacheEntry>>> = 
        Arc::new(Mutex::new(HashMap::new()));
}

const CACHE_TTL_SECONDS: u64 = 300; // 5 minute cache

#[derive(Debug, Serialize, Deserialize)]
struct ClaudeSettings {
    env: Option<HashMap<String, serde_json::Value>>,
}

fn get_current_timestamp() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap()
        .as_secs()
}

fn get_directory_hash(claude_path: &PathBuf) -> Result<String, String> {
    let projects_dir = claude_path.join("projects");
    use std::hash::Hasher;
    let mut hasher = std::collections::hash_map::DefaultHasher::new();
    
    if let Ok(entries) = fs::read_dir(&projects_dir) {
        let mut files: Vec<_> = entries
            .flatten()
            .filter_map(|entry| {
                let path = entry.path();
                if path.is_dir() {
                    Some((path, entry.metadata().ok()?.modified().ok()?))
                } else {
                    None
                }
            })
            .collect();
        
        files.sort_by_key(|(path, _)| path.clone());
        
        for (path, modified) in files {
            use std::hash::Hash;
            path.hash(&mut hasher);
            if let Ok(duration) = modified.duration_since(UNIX_EPOCH) {
                duration.as_secs().hash(&mut hasher);
            }
        }
    }
    
    Ok(format!("{:x}", hasher.finish()))
}

fn is_cache_valid(entry: &UsageCacheEntry, current_hash: &str) -> bool {
    let current_time = get_current_timestamp();
    let is_fresh = (current_time - entry.timestamp) < CACHE_TTL_SECONDS;
    let hash_matches = entry.file_hash == current_hash;
    
    is_fresh && hash_matches
}

fn get_api_base_url() -> String {
    // First check environment variable
    if let Ok(api_base_url) = env::var("ANTHROPIC_BASE_URL") {
        return api_base_url;
    }
    
    // Then check Claude settings.json
    if let Some(home_dir) = dirs::home_dir() {
        let settings_path = home_dir.join(".claude").join("settings.json");
        if let Ok(settings_content) = fs::read_to_string(&settings_path) {
            if let Ok(settings) = serde_json::from_str::<ClaudeSettings>(&settings_content) {
                if let Some(env_vars) = settings.env {
                    if let Some(api_base_url) = env_vars.get("ANTHROPIC_BASE_URL") {
                        if let Some(url_str) = api_base_url.as_str() {
                            return url_str.to_string();
                        }
                    }
                }
            }
        }
    }
    
    // Default fallback
    "https://api.anthropic.com".to_string()
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct UsageEntry {
    timestamp: String,
    model: String,
    input_tokens: u64,
    output_tokens: u64,
    cache_creation_tokens: u64,
    cache_read_tokens: u64,
    cost: f64,
    session_id: String,
    project_path: String,
    api_base_url: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct UsageStats {
    total_cost: f64,
    total_tokens: u64,
    total_input_tokens: u64,
    total_output_tokens: u64,
    total_cache_creation_tokens: u64,
    total_cache_read_tokens: u64,
    total_sessions: u64,
    by_model: Vec<ModelUsage>,
    by_date: Vec<DailyUsage>,
    by_project: Vec<ProjectUsage>,
    by_api_base_url: Vec<ApiBaseUrlUsage>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ModelUsage {
    model: String,
    total_cost: f64,
    total_tokens: u64,
    input_tokens: u64,
    output_tokens: u64,
    cache_creation_tokens: u64,
    cache_read_tokens: u64,
    session_count: u64,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DailyUsage {
    date: String,
    total_cost: f64,
    total_tokens: u64,
    models_used: Vec<String>,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ProjectUsage {
    project_path: String,
    project_name: String,
    total_cost: f64,
    total_tokens: u64,
    session_count: u64,
    last_used: String,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ApiBaseUrlUsage {
    api_base_url: String,
    total_cost: f64,
    total_tokens: u64,
    input_tokens: u64,
    output_tokens: u64,
    cache_creation_tokens: u64,
    cache_read_tokens: u64,
    session_count: u64,
}

// Claude 4 pricing constants (per million tokens) - Updated January 2025
const OPUS_4_INPUT_PRICE: f64 = 15.0;
const OPUS_4_OUTPUT_PRICE: f64 = 75.0;
const OPUS_4_CACHE_WRITE_PRICE: f64 = 18.75;
const OPUS_4_CACHE_READ_PRICE: f64 = 1.50;

const SONNET_4_INPUT_PRICE: f64 = 3.0;
const SONNET_4_OUTPUT_PRICE: f64 = 15.0;
const SONNET_4_CACHE_WRITE_PRICE: f64 = 3.75;
const SONNET_4_CACHE_READ_PRICE: f64 = 0.30;

// Claude 3.7 pricing constants (per million tokens)
const SONNET_37_INPUT_PRICE: f64 = 3.0;
const SONNET_37_OUTPUT_PRICE: f64 = 15.0;
const SONNET_37_CACHE_WRITE_PRICE: f64 = 3.75;
const SONNET_37_CACHE_READ_PRICE: f64 = 0.30;

// Claude 3.5 pricing constants (per million tokens)
const SONNET_35_INPUT_PRICE: f64 = 3.0;
const SONNET_35_OUTPUT_PRICE: f64 = 15.0;
const SONNET_35_CACHE_WRITE_PRICE: f64 = 3.75;
const SONNET_35_CACHE_READ_PRICE: f64 = 0.30;

// Claude Code session window duration (5 hours)
const SESSION_WINDOW_HOURS: i64 = 5;

// Helper function to check if a session is still active based on Claude Code's 5-hour window
#[allow(dead_code)]
fn is_session_active(session_start: &str, current_time: &DateTime<Local>) -> bool {
    if let Ok(start_time) = DateTime::parse_from_rfc3339(session_start) {
        let elapsed = current_time.signed_duration_since(start_time);
        elapsed.num_hours() < SESSION_WINDOW_HOURS
    } else {
        false
    }
}

// Enhanced session tracking with time window awareness
fn track_active_sessions(entries: &[UsageEntry]) -> HashMap<String, DateTime<Local>> {
    let mut session_starts: HashMap<String, DateTime<Local>> = HashMap::new();
    
    for entry in entries {
        if let Ok(entry_time) = DateTime::parse_from_rfc3339(&entry.timestamp) {
            let local_time = entry_time.with_timezone(&Local);
            
            // Track the earliest timestamp for each session
            session_starts
                .entry(entry.session_id.clone())
                .and_modify(|start| {
                    if local_time < *start {
                        *start = local_time;
                    }
                })
                .or_insert(local_time);
        }
    }
    
    session_starts
}

#[derive(Debug, Deserialize)]
struct JsonlEntry {
    timestamp: String,
    message: Option<MessageData>,
    #[serde(rename = "sessionId")]
    session_id: Option<String>,
    #[serde(rename = "requestId")]
    request_id: Option<String>,
    #[serde(rename = "costUSD")]
    cost_usd: Option<f64>,
}

#[derive(Debug, Deserialize)]
struct MessageData {
    id: Option<String>,
    model: Option<String>,
    usage: Option<UsageData>,
}

#[derive(Debug, Deserialize)]
struct UsageData {
    input_tokens: Option<u64>,
    output_tokens: Option<u64>,
    cache_creation_input_tokens: Option<u64>,
    cache_read_input_tokens: Option<u64>,
}

fn calculate_cost(model: &str, usage: &UsageData) -> f64 {
    let input_tokens = usage.input_tokens.unwrap_or(0) as f64;
    let output_tokens = usage.output_tokens.unwrap_or(0) as f64;
    let cache_creation_tokens = usage.cache_creation_input_tokens.unwrap_or(0) as f64;
    let cache_read_tokens = usage.cache_read_input_tokens.unwrap_or(0) as f64;

    // Calculate cost based on model - improved pattern matching
    let (input_price, output_price, cache_write_price, cache_read_price) =
        if model.contains("opus-4") || model.contains("claude-opus-4") {
            (
                OPUS_4_INPUT_PRICE,
                OPUS_4_OUTPUT_PRICE,
                OPUS_4_CACHE_WRITE_PRICE,
                OPUS_4_CACHE_READ_PRICE,
            )
        } else if model.contains("sonnet-4") || model.contains("claude-sonnet-4") {
            (
                SONNET_4_INPUT_PRICE,
                SONNET_4_OUTPUT_PRICE,
                SONNET_4_CACHE_WRITE_PRICE,
                SONNET_4_CACHE_READ_PRICE,
            )
        } else if model.contains("sonnet-3.7") || model.contains("claude-sonnet-3.7") {
            (
                SONNET_37_INPUT_PRICE,
                SONNET_37_OUTPUT_PRICE,
                SONNET_37_CACHE_WRITE_PRICE,
                SONNET_37_CACHE_READ_PRICE,
            )
        } else if model.contains("sonnet-3.5") || model.contains("claude-sonnet-3.5") {
            (
                SONNET_35_INPUT_PRICE,
                SONNET_35_OUTPUT_PRICE,
                SONNET_35_CACHE_WRITE_PRICE,
                SONNET_35_CACHE_READ_PRICE,
            )
        } else {
            // Return 0 for unknown models to avoid incorrect cost estimations (Old version logic)
            (0.0, 0.0, 0.0, 0.0)
        };

    // Calculate cost (prices are per million tokens)
    let cost = (input_tokens * input_price / 1_000_000.0)
        + (output_tokens * output_price / 1_000_000.0)
        + (cache_creation_tokens * cache_write_price / 1_000_000.0)
        + (cache_read_tokens * cache_read_price / 1_000_000.0);

    cost
}

fn parse_jsonl_file(
    path: &PathBuf,
    encoded_project_name: &str,
    processed_hashes: &mut HashSet<String>,
) -> Vec<UsageEntry> {
    let mut entries = Vec::new();
    let mut actual_project_path: Option<String> = None;

    if let Ok(content) = fs::read_to_string(path) {
        // Extract session ID from the file path
        let session_id = path
            .parent()
            .and_then(|p| p.file_name())
            .and_then(|n| n.to_str())
            .unwrap_or("unknown")
            .to_string();

        for line in content.lines() {
            if line.trim().is_empty() {
                continue;
            }

            if let Ok(json_value) = serde_json::from_str::<serde_json::Value>(line) {
                // Extract the actual project path from cwd if we haven't already
                if actual_project_path.is_none() {
                    if let Some(cwd) = json_value.get("cwd").and_then(|v| v.as_str()) {
                        actual_project_path = Some(cwd.to_string());
                    }
                }

                // Get API Base URL from configuration
                let api_base_url = get_api_base_url();

                // Try to parse as JsonlEntry for usage data
                if let Ok(entry) = serde_json::from_value::<JsonlEntry>(json_value.clone()) {
                    if let Some(message) = &entry.message {
                        if let Some(usage) = &message.usage {
                            // Smart deduplication strategy: combine the advantages of both versions (most realistic statistics)
                            let has_io_tokens = usage.input_tokens.unwrap_or(0) > 0 || usage.output_tokens.unwrap_or(0) > 0;
                            let has_cache_tokens = usage.cache_creation_input_tokens.unwrap_or(0) > 0 || usage.cache_read_input_tokens.unwrap_or(0) > 0;
                            
                            if has_io_tokens {
                                // Use strict deduplication for input/output tokens (ensure accuracy)
                                if let Some(msg_id) = &message.id {
                                    let unique_hash = format!("io:{}:{}", session_id, msg_id);
                                    if processed_hashes.contains(&unique_hash) {
                                        continue; // Skip duplicate IO entry
                                    }
                                    processed_hashes.insert(unique_hash);
                                }
                            } else if has_cache_tokens {
                                // Use loose deduplication for cached tokens (maintain accuracy)
                                if let (Some(msg_id), Some(req_id)) = (&message.id, &entry.request_id) {
                                    let unique_hash = format!("cache:{}:{}", msg_id, req_id);
                                    if processed_hashes.contains(&unique_hash) {
                                        continue; // Skip duplicate cache entry
                                    }
                                    processed_hashes.insert(unique_hash);
                                }
                            }
                            // Skip entries without meaningful token usage
                            if usage.input_tokens.unwrap_or(0) == 0
                                && usage.output_tokens.unwrap_or(0) == 0
                                && usage.cache_creation_input_tokens.unwrap_or(0) == 0
                                && usage.cache_read_input_tokens.unwrap_or(0) == 0
                            {
                                continue;
                            }

                            let cost = entry.cost_usd.unwrap_or_else(|| {
                                if let Some(model_str) = &message.model {
                                    calculate_cost(model_str, usage)
                                } else {
                                    0.0
                                }
                            });

                            // Use actual project path if found, otherwise use encoded name
                            let project_path = actual_project_path
                                .clone()
                                .unwrap_or_else(|| encoded_project_name.to_string());

                            entries.push(UsageEntry {
                                timestamp: entry.timestamp,
                                model: message
                                    .model
                                    .clone()
                                    .unwrap_or_else(|| "unknown".to_string()),
                                input_tokens: usage.input_tokens.unwrap_or(0),
                                output_tokens: usage.output_tokens.unwrap_or(0),
                                cache_creation_tokens: usage
                                    .cache_creation_input_tokens
                                    .unwrap_or(0),
                                cache_read_tokens: usage.cache_read_input_tokens.unwrap_or(0),
                                cost,
                                session_id: entry.session_id.unwrap_or_else(|| session_id.clone()),
                                project_path,
                                api_base_url,
                            });
                        }
                    }
                }
            }
        }
    }

    entries
}

fn get_earliest_timestamp(path: &PathBuf) -> Option<String> {
    if let Ok(content) = fs::read_to_string(path) {
        let mut earliest_timestamp: Option<String> = None;
        for line in content.lines() {
            if let Ok(json_value) = serde_json::from_str::<serde_json::Value>(line) {
                if let Some(timestamp_str) = json_value.get("timestamp").and_then(|v| v.as_str()) {
                    if let Some(current_earliest) = &earliest_timestamp {
                        if timestamp_str < current_earliest.as_str() {
                            earliest_timestamp = Some(timestamp_str.to_string());
                        }
                    } else {
                        earliest_timestamp = Some(timestamp_str.to_string());
                    }
                }
            }
        }
        return earliest_timestamp;
    }
    None
}

fn get_all_usage_entries_optimized(claude_path: &PathBuf) -> Vec<UsageEntry> {
    let mut all_entries = Vec::new();
    let mut processed_hashes = HashSet::new();
    let projects_dir = claude_path.join("projects");

    // Use Vec to store file paths and modification times for batch processing
    let mut files_to_process: Vec<(PathBuf, String, SystemTime)> = Vec::new();

    if let Ok(projects) = fs::read_dir(&projects_dir) {
        for project in projects.flatten() {
            if project.file_type().map(|t| t.is_dir()).unwrap_or(false) {
                let project_name = project.file_name().to_string_lossy().to_string();
                let project_path = project.path();

                // Use more efficient file traversal
                if let Ok(walker) = std::fs::read_dir(&project_path) {
                    for entry in walker.flatten() {
                        let path = entry.path();
                        if path.extension().and_then(|s| s.to_str()) == Some("jsonl") {
                            if let Ok(metadata) = entry.metadata() {
                                if let Ok(modified) = metadata.modified() {
                                    files_to_process.push((path, project_name.clone(), modified));
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    // Sort by modification time, process newest files first
    files_to_process.sort_by_key(|(_, _, modified)| std::cmp::Reverse(*modified));

    // Batch process files, limit memory usage
    const BATCH_SIZE: usize = 10;
    for batch in files_to_process.chunks(BATCH_SIZE) {
        for (path, project_name, _) in batch {
            let entries = parse_jsonl_file_fast(path, project_name, &mut processed_hashes);
            all_entries.extend(entries);
            
            // Check memory usage after each batch (simple limit)
            if all_entries.len() > 50000 {
                log::warn!("Usage entries limit reached, stopping early to prevent memory issues");
                break;
            }
        }
    }

    // Only keep recent entries sorted (performance improvement)
    all_entries.sort_unstable_by(|a, b| b.timestamp.cmp(&a.timestamp));

    all_entries
}

// Optimized JSON parsing function
fn parse_jsonl_file_fast(
    path: &PathBuf,
    encoded_project_name: &str,
    processed_hashes: &mut HashSet<String>,
) -> Vec<UsageEntry> {
    let mut entries = Vec::new();
    let mut actual_project_path: Option<String> = None;

    // Use BufReader to improve large file reading performance
    let file = match std::fs::File::open(path) {
        Ok(f) => f,
        Err(_) => return entries,
    };
    
    let reader = std::io::BufReader::new(file);
    use std::io::BufRead;

    // Extract session ID
    let session_id = path
        .parent()
        .and_then(|p| p.file_name())
        .and_then(|n| n.to_str())
        .unwrap_or("unknown")
        .to_string();

    let mut line_count = 0;
    const MAX_LINES_PER_FILE: usize = 10000; // Limit single file processing lines

    for line_result in reader.lines() {
        line_count += 1;
        if line_count > MAX_LINES_PER_FILE {
            log::warn!("File {} has too many lines, processing first {} lines only", 
                path.display(), MAX_LINES_PER_FILE);
            break;
        }

        let line = match line_result {
            Ok(l) => l,
            Err(_) => continue,
        };

        if line.trim().is_empty() {
            continue;
        }

        // Fast JSON parsing
        let json_value: serde_json::Value = match serde_json::from_str(&line) {
            Ok(v) => v,
            Err(_) => continue,
        };

        // Extract project path (only for the first time)
        if actual_project_path.is_none() {
            if let Some(cwd) = json_value.get("cwd").and_then(|v| v.as_str()) {
                actual_project_path = Some(cwd.to_string());
            }
        }

        // Fast parsing of usage data
        if let Some(message) = json_value.get("message") {
            if let Some(usage) = message.get("usage") {
                let input_tokens = usage.get("input_tokens").and_then(|v| v.as_u64()).unwrap_or(0);
                let output_tokens = usage.get("output_tokens").and_then(|v| v.as_u64()).unwrap_or(0);
                let cache_creation_tokens = usage.get("cache_creation_input_tokens").and_then(|v| v.as_u64()).unwrap_or(0);
                let cache_read_tokens = usage.get("cache_read_input_tokens").and_then(|v| v.as_u64()).unwrap_or(0);
                
                // Skip meaningless entries
                if input_tokens == 0 && output_tokens == 0 && cache_creation_tokens == 0 && cache_read_tokens == 0 {
                    continue;
                }

                // Simplify deduplication logic
                if let Some(msg_id) = message.get("id").and_then(|v| v.as_str()) {
                    let unique_hash = format!("{}:{}", session_id, msg_id);
                    if processed_hashes.contains(&unique_hash) {
                        continue;
                    }
                    processed_hashes.insert(unique_hash);
                }

                let model_str = message.get("model").and_then(|v| v.as_str()).unwrap_or("unknown");
                
                // Fast cost calculation
                let cost = if let Some(cost_usd) = json_value.get("costUSD").and_then(|v| v.as_f64()) {
                    cost_usd
                } else {
                    calculate_cost_fast(model_str, input_tokens, output_tokens, cache_creation_tokens, cache_read_tokens)
                };

                let project_path = actual_project_path
                    .clone()
                    .unwrap_or_else(|| encoded_project_name.to_string());

                entries.push(UsageEntry {
                    timestamp: json_value.get("timestamp").and_then(|v| v.as_str()).unwrap_or("").to_string(),
                    model: model_str.to_string(),
                    input_tokens,
                    output_tokens,
                    cache_creation_tokens,
                    cache_read_tokens,
                    cost,
                    session_id: json_value.get("sessionId").and_then(|v| v.as_str()).unwrap_or(&session_id).to_string(),
                    project_path,
                    api_base_url: get_api_base_url(),
                });
            }
        }
    }

    entries
}

// Optimized cost calculation function
fn calculate_cost_fast(model: &str, input_tokens: u64, output_tokens: u64, cache_creation_tokens: u64, cache_read_tokens: u64) -> f64 {
    let (input_price, output_price, cache_write_price, cache_read_price) = match model {
        m if m.contains("opus-4") || m.contains("claude-opus-4") =>
            (OPUS_4_INPUT_PRICE, OPUS_4_OUTPUT_PRICE, OPUS_4_CACHE_WRITE_PRICE, OPUS_4_CACHE_READ_PRICE),
        m if m.contains("sonnet-4") || m.contains("claude-sonnet-4") =>
            (SONNET_4_INPUT_PRICE, SONNET_4_OUTPUT_PRICE, SONNET_4_CACHE_WRITE_PRICE, SONNET_4_CACHE_READ_PRICE),
        m if m.contains("sonnet-3.7") || m.contains("claude-sonnet-3.7") =>
            (SONNET_37_INPUT_PRICE, SONNET_37_OUTPUT_PRICE, SONNET_37_CACHE_WRITE_PRICE, SONNET_37_CACHE_READ_PRICE),
        m if m.contains("sonnet-3.5") || m.contains("claude-sonnet-3.5") =>
            (SONNET_35_INPUT_PRICE, SONNET_35_OUTPUT_PRICE, SONNET_35_CACHE_WRITE_PRICE, SONNET_35_CACHE_READ_PRICE),
        _ => (0.0, 0.0, 0.0, 0.0),
    };

    // Direct calculation, avoid unnecessary type conversion
    ((input_tokens as f64 * input_price) +
     (output_tokens as f64 * output_price) +
     (cache_creation_tokens as f64 * cache_write_price) +
     (cache_read_tokens as f64 * cache_read_price)) / 1_000_000.0
}

fn get_all_usage_entries(claude_path: &PathBuf) -> Vec<UsageEntry> {
    let mut all_entries = Vec::new();
    let mut processed_hashes = HashSet::new();
    let projects_dir = claude_path.join("projects");

    let mut files_to_process: Vec<(PathBuf, String)> = Vec::new();

    if let Ok(projects) = fs::read_dir(&projects_dir) {
        for project in projects.flatten() {
            if project.file_type().map(|t| t.is_dir()).unwrap_or(false) {
                let project_name = project.file_name().to_string_lossy().to_string();
                let project_path = project.path();

                walkdir::WalkDir::new(&project_path)
                    .into_iter()
                    .filter_map(Result::ok)
                    .filter(|e| e.path().extension().and_then(|s| s.to_str()) == Some("jsonl"))
                    .for_each(|entry| {
                        files_to_process.push((entry.path().to_path_buf(), project_name.clone()));
                    });
            }
        }
    }

    // Sort files by their earliest timestamp to ensure chronological processing
    // and deterministic deduplication.
    files_to_process.sort_by_cached_key(|(path, _)| get_earliest_timestamp(path));

    for (path, project_name) in files_to_process {
        let entries = parse_jsonl_file(&path, &project_name, &mut processed_hashes);
        all_entries.extend(entries);
    }

    // Sort by timestamp
    all_entries.sort_by(|a, b| a.timestamp.cmp(&b.timestamp));

    all_entries
}

#[command]
pub fn get_usage_stats(days: Option<u32>) -> Result<UsageStats, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    // Generate cache key
    let cache_key = format!("usage_stats_{}", days.unwrap_or(0));
    
    // Check cache
    let current_hash = get_directory_hash(&claude_path)?;
    
    // Try to get from cache
    if let Ok(cache) = USAGE_CACHE.lock() {
        if let Some(cached_entry) = cache.get(&cache_key) {
            if is_cache_valid(cached_entry, &current_hash) {
                log::debug!("Using cached usage stats for key: {}", cache_key);
                return Ok(cached_entry.data.clone());
            }
        }
    }

    // Use optimized data retrieval function
    let all_entries = get_all_usage_entries_optimized(&claude_path);

    if all_entries.is_empty() {
        let empty_stats = UsageStats {
            total_cost: 0.0,
            total_tokens: 0,
            total_input_tokens: 0,
            total_output_tokens: 0,
            total_cache_creation_tokens: 0,
            total_cache_read_tokens: 0,
            total_sessions: 0,
            by_model: vec![],
            by_date: vec![],
            by_project: vec![],
            by_api_base_url: vec![],
        };
        
        // Cache empty results
        if let Ok(mut cache) = USAGE_CACHE.lock() {
            cache.insert(cache_key, UsageCacheEntry {
                data: empty_stats.clone(),
                timestamp: get_current_timestamp(),
                file_hash: current_hash,
            });
        }
        
        return Ok(empty_stats);
    }

    // Filter by days if specified
    let filtered_entries = if let Some(days) = days {
        let cutoff = Local::now().naive_local().date() - chrono::Duration::days(days as i64);
        all_entries
            .into_iter()
            .filter(|e| {
                if let Ok(dt) = DateTime::parse_from_rfc3339(&e.timestamp) {
                    dt.naive_local().date() >= cutoff
                } else {
                    false
                }
            })
            .collect()
    } else {
        all_entries
    };

    // Use optimized statistics calculation
    let stats = calculate_usage_stats_fast(&filtered_entries);
    
    // Cache results
    if let Ok(mut cache) = USAGE_CACHE.lock() {
        cache.insert(cache_key, UsageCacheEntry {
            data: stats.clone(),
            timestamp: get_current_timestamp(),
            file_hash: current_hash,
        });
        
        // Limit cache size
        if cache.len() > 20 {
            let keys_to_remove: Vec<String> = cache.keys().take(5).cloned().collect();
            for key in keys_to_remove {
                cache.remove(&key);
            }
        }
    }

    Ok(stats)
}

// Optimized statistics calculation function
fn calculate_usage_stats_fast(filtered_entries: &[UsageEntry]) -> UsageStats {
    // Pre-allocate capacity to improve performance
    let mut model_stats: HashMap<String, ModelUsage> = HashMap::with_capacity(10);
    let mut daily_stats: HashMap<String, DailyUsage> = HashMap::with_capacity(100);
    let mut project_stats: HashMap<String, ProjectUsage> = HashMap::with_capacity(50);
    let mut api_base_url_stats: HashMap<String, ApiBaseUrlUsage> = HashMap::with_capacity(5);
    
    // Use HashSet to track unique sessions, pre-allocate capacity
    let mut unique_sessions: HashSet<String> = HashSet::with_capacity(1000);
    let mut model_sessions: HashMap<String, HashSet<String>> = HashMap::with_capacity(10);
    let mut project_sessions: HashMap<String, HashSet<String>> = HashMap::with_capacity(50);
    let mut api_sessions: HashMap<String, HashSet<String>> = HashMap::with_capacity(5);

    let mut total_cost = 0.0;
    let mut total_input_tokens = 0u64;
    let mut total_output_tokens = 0u64;
    let mut total_cache_creation_tokens = 0u64;
    let mut total_cache_read_tokens = 0u64;

    for entry in filtered_entries {
        // Cumulative total
        total_cost += entry.cost;
        total_input_tokens += entry.input_tokens;
        total_output_tokens += entry.output_tokens;
        total_cache_creation_tokens += entry.cache_creation_tokens;
        total_cache_read_tokens += entry.cache_read_tokens;

        // Track unique sessions
        unique_sessions.insert(entry.session_id.clone());
        
        // Model session tracking
        model_sessions
            .entry(entry.model.clone())
            .or_insert_with(|| HashSet::with_capacity(100))
            .insert(entry.session_id.clone());
            
        // Project session tracking
        project_sessions
            .entry(entry.project_path.clone())
            .or_insert_with(|| HashSet::with_capacity(50))
            .insert(entry.session_id.clone());
            
        // API session tracking
        api_sessions
            .entry(entry.api_base_url.clone())
            .or_insert_with(|| HashSet::with_capacity(10))
            .insert(entry.session_id.clone());

        // Update model statistics
        let model_stat = model_stats.entry(entry.model.clone()).or_insert_with(|| ModelUsage {
            model: entry.model.clone(),
            total_cost: 0.0,
            total_tokens: 0,
            input_tokens: 0,
            output_tokens: 0,
            cache_creation_tokens: 0,
            cache_read_tokens: 0,
            session_count: 0,
        });
        
        model_stat.total_cost += entry.cost;
        model_stat.input_tokens += entry.input_tokens;
        model_stat.output_tokens += entry.output_tokens;
        model_stat.cache_creation_tokens += entry.cache_creation_tokens;
        model_stat.cache_read_tokens += entry.cache_read_tokens;
        model_stat.total_tokens = model_stat.input_tokens + model_stat.output_tokens 
            + model_stat.cache_creation_tokens + model_stat.cache_read_tokens;

        // Update daily statistics
        let date = entry.timestamp.split('T').next().unwrap_or(&entry.timestamp).to_string();
        let daily_stat = daily_stats.entry(date.clone()).or_insert_with(|| DailyUsage {
            date,
            total_cost: 0.0,
            total_tokens: 0,
            models_used: Vec::with_capacity(5),
        });
        
        daily_stat.total_cost += entry.cost;
        daily_stat.total_tokens += entry.input_tokens + entry.output_tokens 
            + entry.cache_creation_tokens + entry.cache_read_tokens;
            
        if !daily_stat.models_used.contains(&entry.model) {
            daily_stat.models_used.push(entry.model.clone());
        }

        // Update project statistics
        let project_name = entry.project_path.split('/').last().unwrap_or(&entry.project_path).to_string();
        let project_stat = project_stats.entry(entry.project_path.clone()).or_insert_with(|| ProjectUsage {
            project_path: entry.project_path.clone(),
            project_name,
            total_cost: 0.0,
            total_tokens: 0,
            session_count: 0,
            last_used: entry.timestamp.clone(),
        });
        
        project_stat.total_cost += entry.cost;
        project_stat.total_tokens += entry.input_tokens + entry.output_tokens 
            + entry.cache_creation_tokens + entry.cache_read_tokens;
            
        if entry.timestamp > project_stat.last_used {
            project_stat.last_used = entry.timestamp.clone();
        }

        // Update API URL statistics
        let api_stat = api_base_url_stats.entry(entry.api_base_url.clone()).or_insert_with(|| ApiBaseUrlUsage {
            api_base_url: entry.api_base_url.clone(),
            total_cost: 0.0,
            total_tokens: 0,
            input_tokens: 0,
            output_tokens: 0,
            cache_creation_tokens: 0,
            cache_read_tokens: 0,
            session_count: 0,
        });
        
        api_stat.total_cost += entry.cost;
        api_stat.input_tokens += entry.input_tokens;
        api_stat.output_tokens += entry.output_tokens;
        api_stat.cache_creation_tokens += entry.cache_creation_tokens;
        api_stat.cache_read_tokens += entry.cache_read_tokens;
        api_stat.total_tokens = api_stat.input_tokens + api_stat.output_tokens 
            + api_stat.cache_creation_tokens + api_stat.cache_read_tokens;
    }

    let total_tokens = total_input_tokens + total_output_tokens 
        + total_cache_creation_tokens + total_cache_read_tokens;
    let total_sessions = unique_sessions.len() as u64;

    // Set session count and convert to sorted vector
    let mut by_model: Vec<ModelUsage> = model_stats.into_iter().map(|(model, mut stat)| {
        stat.session_count = model_sessions.get(&model).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_model.sort_unstable_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_date: Vec<DailyUsage> = daily_stats.into_values().collect();
    by_date.sort_unstable_by(|a, b| b.date.cmp(&a.date));

    let mut by_project: Vec<ProjectUsage> = project_stats.into_iter().map(|(project_path, mut stat)| {
        stat.session_count = project_sessions.get(&project_path).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_project.sort_unstable_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_api_base_url: Vec<ApiBaseUrlUsage> = api_base_url_stats.into_iter().map(|(api_url, mut stat)| {
        stat.session_count = api_sessions.get(&api_url).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_api_base_url.sort_unstable_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    UsageStats {
        total_cost,
        total_tokens,
        total_input_tokens,
        total_output_tokens,
        total_cache_creation_tokens,
        total_cache_read_tokens,
        total_sessions,
        by_model,
        by_date,
        by_project,
        by_api_base_url,
    }
}

// Paginated statistics data structure
#[allow(dead_code)]
#[derive(Debug, Serialize)]
pub struct PaginatedUsageStats {
    total_cost: f64,
    total_tokens: u64,
    total_input_tokens: u64,
    total_output_tokens: u64,
    total_cache_creation_tokens: u64,
    total_cache_read_tokens: u64,
    total_sessions: u64,
    // Paginated data
    by_model: PaginatedData<ModelUsage>,
    by_project: PaginatedData<ProjectUsage>,
    by_api_base_url: PaginatedData<ApiBaseUrlUsage>,
    by_date: Vec<DailyUsage>, // Date data is usually not much, no pagination needed
}

#[allow(dead_code)]
#[derive(Debug, Serialize)]
pub struct PaginatedData<T> {
    data: Vec<T>,
    total_count: usize,
    page: usize,
    page_size: usize,
    has_more: bool,
}

#[derive(Debug, Serialize)]
pub struct UsageOverview {
    total_cost: f64,
    total_sessions: u64,
    total_tokens: u64,
    today_cost: f64,
    week_cost: f64,
    top_model: Option<String>,
    top_project: Option<String>,
}

// Quick overview statistics (fastest loading)
#[command]
pub fn get_usage_overview() -> Result<UsageOverview, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    // Only load recent data for overview statistics
    let recent_entries = get_recent_usage_entries(&claude_path, 1000)?; // Up to 1000 records
    
    if recent_entries.is_empty() {
        return Ok(UsageOverview {
            total_cost: 0.0,
            total_sessions: 0,
            total_tokens: 0,
            today_cost: 0.0,
            week_cost: 0.0,
            top_model: None,
            top_project: None,
        });
    }

    let now = Local::now();
    let today = now.date_naive();
    let week_ago = now.date_naive() - chrono::Duration::days(7);

    let mut total_cost = 0.0;
    let mut total_tokens = 0u64;
    let mut today_cost = 0.0;
    let mut week_cost = 0.0;
    let mut unique_sessions = HashSet::new();
    let mut model_costs: HashMap<String, f64> = HashMap::new();
    let mut project_costs: HashMap<String, f64> = HashMap::new();

    for entry in &recent_entries {
        total_cost += entry.cost;
        total_tokens += entry.input_tokens + entry.output_tokens + 
                       entry.cache_creation_tokens + entry.cache_read_tokens;
        unique_sessions.insert(entry.session_id.clone());
        
        *model_costs.entry(entry.model.clone()).or_insert(0.0) += entry.cost;
        *project_costs.entry(entry.project_path.clone()).or_insert(0.0) += entry.cost;

        if let Ok(dt) = DateTime::parse_from_rfc3339(&entry.timestamp) {
            let date = dt.date_naive();
            if date == today {
                today_cost += entry.cost;
            }
            if date >= week_ago {
                week_cost += entry.cost;
            }
        }
    }

    let top_model = model_costs.into_iter()
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap())
        .map(|(model, _)| model);

    let top_project = project_costs.into_iter()
        .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap())
        .map(|(project, _)| project);

    Ok(UsageOverview {
        total_cost,
        total_sessions: unique_sessions.len() as u64,
        total_tokens,
        today_cost,
        week_cost,
        top_model,
        top_project,
    })
}

// Get recent usage entries (limited quantity)
fn get_recent_usage_entries(claude_path: &PathBuf, limit: usize) -> Result<Vec<UsageEntry>, String> {
    let mut all_entries = Vec::with_capacity(limit);
    let mut processed_hashes = HashSet::new();
    let projects_dir = claude_path.join("projects");

    if !projects_dir.exists() {
        return Ok(all_entries);
    }

    // Get all JSONL files and sort by modification time
    let mut files_with_time: Vec<(PathBuf, String, SystemTime)> = Vec::new();

    if let Ok(projects) = fs::read_dir(&projects_dir) {
        for project in projects.flatten() {
            if project.file_type().map(|t| t.is_dir()).unwrap_or(false) {
                let project_name = project.file_name().to_string_lossy().to_string();
                let project_path = project.path();

                if let Ok(walker) = std::fs::read_dir(&project_path) {
                    for entry in walker.flatten() {
                        let path = entry.path();
                        if path.extension().and_then(|s| s.to_str()) == Some("jsonl") {
                            if let Ok(metadata) = entry.metadata() {
                                if let Ok(modified) = metadata.modified() {
                                    files_with_time.push((path, project_name.clone(), modified));
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    // Sort by modification time in descending order, process newest files first
    files_with_time.sort_by_key(|(_, _, modified)| std::cmp::Reverse(*modified));

    // Only process the newest files
    let files_to_process = files_with_time.into_iter().take(20); // Up to 20 newest files

    for (path, project_name, _) in files_to_process {
        let entries = parse_jsonl_file_fast(&path, &project_name, &mut processed_hashes);
        all_entries.extend(entries);
        
        // Stop processing if limit is reached
        if all_entries.len() >= limit {
            break;
        }
    }

    // Sort by time in descending order and truncate
    all_entries.sort_unstable_by(|a, b| b.timestamp.cmp(&a.timestamp));
    all_entries.truncate(limit);

    Ok(all_entries)
}

#[command]
pub fn get_usage_by_date_range(start_date: String, end_date: String) -> Result<UsageStats, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);

    // Parse dates
    let start = NaiveDate::parse_from_str(&start_date, "%Y-%m-%d").or_else(|_| {
        // Try parsing ISO datetime format
        DateTime::parse_from_rfc3339(&start_date)
            .map(|dt| dt.naive_local().date())
            .map_err(|e| format!("Invalid start date: {}", e))
    })?;
    let end = NaiveDate::parse_from_str(&end_date, "%Y-%m-%d").or_else(|_| {
        // Try parsing ISO datetime format
        DateTime::parse_from_rfc3339(&end_date)
            .map(|dt| dt.naive_local().date())
            .map_err(|e| format!("Invalid end date: {}", e))
    })?;

    // Filter entries by date range
    let filtered_entries: Vec<_> = all_entries
        .into_iter()
        .filter(|e| {
            if let Ok(dt) = DateTime::parse_from_rfc3339(&e.timestamp) {
                let date = dt.naive_local().date();
                date >= start && date <= end
            } else {
                false
            }
        })
        .collect();

    if filtered_entries.is_empty() {
        return Ok(UsageStats {
            total_cost: 0.0,
            total_tokens: 0,
            total_input_tokens: 0,
            total_output_tokens: 0,
            total_cache_creation_tokens: 0,
            total_cache_read_tokens: 0,
            total_sessions: 0,
            by_model: vec![],
            by_date: vec![],
            by_project: vec![],
            by_api_base_url: vec![],
        });
    }

    // Calculate aggregated stats (same logic as get_usage_stats)
    let mut total_cost = 0.0;
    let mut total_input_tokens = 0u64;
    let mut total_output_tokens = 0u64;
    let mut total_cache_creation_tokens = 0u64;
    let mut total_cache_read_tokens = 0u64;

    let mut model_stats: HashMap<String, ModelUsage> = HashMap::new();
    let mut daily_stats: HashMap<String, DailyUsage> = HashMap::new();
    let mut project_stats: HashMap<String, ProjectUsage> = HashMap::new();
    let mut api_base_url_stats: HashMap<String, ApiBaseUrlUsage> = HashMap::new();
    
    // Track unique sessions for accurate counting  
    let mut unique_sessions: HashSet<String> = HashSet::new();
    let mut model_sessions: HashMap<String, HashSet<String>> = HashMap::new();
    let mut project_sessions: HashMap<String, HashSet<String>> = HashMap::new();
    let mut api_sessions: HashMap<String, HashSet<String>> = HashMap::new();

    for entry in &filtered_entries {
        // Update totals
        total_cost += entry.cost;
        total_input_tokens += entry.input_tokens;
        total_output_tokens += entry.output_tokens;
        total_cache_creation_tokens += entry.cache_creation_tokens;
        total_cache_read_tokens += entry.cache_read_tokens;

        // Track unique sessions
        unique_sessions.insert(entry.session_id.clone());
        
        // Track sessions per model
        model_sessions
            .entry(entry.model.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());
            
        // Track sessions per project
        project_sessions
            .entry(entry.project_path.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());
            
        // Track sessions per API base URL
        api_sessions
            .entry(entry.api_base_url.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());

        // Update model stats
        let model_stat = model_stats
            .entry(entry.model.clone())
            .or_insert(ModelUsage {
                model: entry.model.clone(),
                total_cost: 0.0,
                total_tokens: 0,
                input_tokens: 0,
                output_tokens: 0,
                cache_creation_tokens: 0,
                cache_read_tokens: 0,
                session_count: 0,
            });
        model_stat.total_cost += entry.cost;
        model_stat.input_tokens += entry.input_tokens;
        model_stat.output_tokens += entry.output_tokens;
        model_stat.cache_creation_tokens += entry.cache_creation_tokens;
        model_stat.cache_read_tokens += entry.cache_read_tokens;
        model_stat.total_tokens = model_stat.input_tokens + model_stat.output_tokens + model_stat.cache_creation_tokens + model_stat.cache_read_tokens;
        // Session count will be set later from unique session tracking

        // Update daily stats
        let date = entry
            .timestamp
            .split('T')
            .next()
            .unwrap_or(&entry.timestamp)
            .to_string();
        let daily_stat = daily_stats.entry(date.clone()).or_insert(DailyUsage {
            date,
            total_cost: 0.0,
            total_tokens: 0,
            models_used: vec![],
        });
        daily_stat.total_cost += entry.cost;
        daily_stat.total_tokens += entry.input_tokens
            + entry.output_tokens
            + entry.cache_creation_tokens
            + entry.cache_read_tokens;
        if !daily_stat.models_used.contains(&entry.model) {
            daily_stat.models_used.push(entry.model.clone());
        }

        // Update project stats
        let project_stat =
            project_stats
                .entry(entry.project_path.clone())
                .or_insert(ProjectUsage {
                    project_path: entry.project_path.clone(),
                    project_name: entry
                        .project_path
                        .split('/')
                        .last()
                        .unwrap_or(&entry.project_path)
                        .to_string(),
                    total_cost: 0.0,
                    total_tokens: 0,
                    session_count: 0,
                    last_used: entry.timestamp.clone(),
                });
        project_stat.total_cost += entry.cost;
        project_stat.total_tokens += entry.input_tokens
            + entry.output_tokens
            + entry.cache_creation_tokens
            + entry.cache_read_tokens;
        // Session count will be set later from unique session tracking
        if entry.timestamp > project_stat.last_used {
            project_stat.last_used = entry.timestamp.clone();
        }

        // Update API base URL stats
        let api_base_url_stat = api_base_url_stats
            .entry(entry.api_base_url.clone())
            .or_insert(ApiBaseUrlUsage {
                api_base_url: entry.api_base_url.clone(),
                total_cost: 0.0,
                total_tokens: 0,
                input_tokens: 0,
                output_tokens: 0,
                cache_creation_tokens: 0,
                cache_read_tokens: 0,
                session_count: 0,
            });
        api_base_url_stat.total_cost += entry.cost;
        api_base_url_stat.input_tokens += entry.input_tokens;
        api_base_url_stat.output_tokens += entry.output_tokens;
        api_base_url_stat.cache_creation_tokens += entry.cache_creation_tokens;
        api_base_url_stat.cache_read_tokens += entry.cache_read_tokens;
        api_base_url_stat.total_tokens = api_base_url_stat.input_tokens + api_base_url_stat.output_tokens + api_base_url_stat.cache_creation_tokens + api_base_url_stat.cache_read_tokens;
        // Session count will be set later from unique session tracking
    }

    let total_tokens = total_input_tokens
        + total_output_tokens
        + total_cache_creation_tokens
        + total_cache_read_tokens;
    let total_sessions = unique_sessions.len() as u64;

    // Set correct session counts and convert hashmaps to sorted vectors
    let mut by_model: Vec<ModelUsage> = model_stats.into_iter().map(|(model, mut stat)| {
        stat.session_count = model_sessions.get(&model).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_model.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_date: Vec<DailyUsage> = daily_stats.into_values().collect();
    by_date.sort_by(|a, b| b.date.cmp(&a.date));

    let mut by_project: Vec<ProjectUsage> = project_stats.into_iter().map(|(project_path, mut stat)| {
        stat.session_count = project_sessions.get(&project_path).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_project.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_api_base_url: Vec<ApiBaseUrlUsage> = api_base_url_stats.into_iter().map(|(api_url, mut stat)| {
        stat.session_count = api_sessions.get(&api_url).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_api_base_url.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    Ok(UsageStats {
        total_cost,
        total_tokens,
        total_input_tokens,
        total_output_tokens,
        total_cache_creation_tokens,
        total_cache_read_tokens,
        total_sessions,
        by_model,
        by_date,
        by_project,
        by_api_base_url,
    })
}

#[command]
pub fn get_usage_details(
    project_path: Option<String>,
    date: Option<String>,
) -> Result<Vec<UsageEntry>, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let mut all_entries = get_all_usage_entries(&claude_path);

    // Filter by project if specified
    if let Some(project) = project_path {
        all_entries.retain(|e| e.project_path == project);
    }

    // Filter by date if specified
    if let Some(date) = date {
        all_entries.retain(|e| e.timestamp.starts_with(&date));
    }

    Ok(all_entries)
}

#[command]
pub fn get_today_usage_stats() -> Result<UsageStats, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);

    // Get today's date
    let today = Local::now().naive_local().date();
    
    // Filter entries for today only
    let today_entries: Vec<_> = all_entries
        .into_iter()
        .filter(|e| {
            if let Ok(dt) = DateTime::parse_from_rfc3339(&e.timestamp) {
                dt.naive_local().date() == today
            } else {
                false
            }
        })
        .collect();

    if today_entries.is_empty() {
        return Ok(UsageStats {
            total_cost: 0.0,
            total_tokens: 0,
            total_input_tokens: 0,
            total_output_tokens: 0,
            total_cache_creation_tokens: 0,
            total_cache_read_tokens: 0,
            total_sessions: 0,
            by_model: vec![],
            by_date: vec![],
            by_project: vec![],
            by_api_base_url: vec![],
        });
    }

    // Calculate aggregated stats for today
    let mut total_cost = 0.0;
    let mut total_input_tokens = 0u64;
    let mut total_output_tokens = 0u64;
    let mut total_cache_creation_tokens = 0u64;
    let mut total_cache_read_tokens = 0u64;

    let mut model_stats: HashMap<String, ModelUsage> = HashMap::new();
    let mut daily_stats: HashMap<String, DailyUsage> = HashMap::new();
    let mut project_stats: HashMap<String, ProjectUsage> = HashMap::new();
    let mut api_base_url_stats: HashMap<String, ApiBaseUrlUsage> = HashMap::new();
    
    // Track unique sessions for accurate counting
    let mut unique_sessions: HashSet<String> = HashSet::new();
    let mut model_sessions: HashMap<String, HashSet<String>> = HashMap::new();
    let mut project_sessions: HashMap<String, HashSet<String>> = HashMap::new();
    let mut api_sessions: HashMap<String, HashSet<String>> = HashMap::new();

    for entry in &today_entries {
        // Update totals
        total_cost += entry.cost;
        total_input_tokens += entry.input_tokens;
        total_output_tokens += entry.output_tokens;
        total_cache_creation_tokens += entry.cache_creation_tokens;
        total_cache_read_tokens += entry.cache_read_tokens;

        // Track unique sessions
        unique_sessions.insert(entry.session_id.clone());
        
        // Track sessions per model
        model_sessions
            .entry(entry.model.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());
            
        // Track sessions per project
        project_sessions
            .entry(entry.project_path.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());
            
        // Track sessions per API base URL
        api_sessions
            .entry(entry.api_base_url.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());

        // Update model stats
        let model_stat = model_stats
            .entry(entry.model.clone())
            .or_insert(ModelUsage {
                model: entry.model.clone(),
                total_cost: 0.0,
                total_tokens: 0,
                input_tokens: 0,
                output_tokens: 0,
                cache_creation_tokens: 0,
                cache_read_tokens: 0,
                session_count: 0,
            });
        model_stat.total_cost += entry.cost;
        model_stat.input_tokens += entry.input_tokens;
        model_stat.output_tokens += entry.output_tokens;
        model_stat.cache_creation_tokens += entry.cache_creation_tokens;
        model_stat.cache_read_tokens += entry.cache_read_tokens;
        model_stat.total_tokens = model_stat.input_tokens + model_stat.output_tokens + model_stat.cache_creation_tokens + model_stat.cache_read_tokens;
        // Session count will be set later from unique session tracking

        // Update daily stats
        let date = entry
            .timestamp
            .split('T')
            .next()
            .unwrap_or(&entry.timestamp)
            .to_string();
        let daily_stat = daily_stats.entry(date.clone()).or_insert(DailyUsage {
            date,
            total_cost: 0.0,
            total_tokens: 0,
            models_used: vec![],
        });
        daily_stat.total_cost += entry.cost;
        daily_stat.total_tokens += entry.input_tokens
            + entry.output_tokens
            + entry.cache_creation_tokens
            + entry.cache_read_tokens;
        if !daily_stat.models_used.contains(&entry.model) {
            daily_stat.models_used.push(entry.model.clone());
        }

        // Update project stats
        let project_stat =
            project_stats
                .entry(entry.project_path.clone())
                .or_insert(ProjectUsage {
                    project_path: entry.project_path.clone(),
                    project_name: entry
                        .project_path
                        .split('/')
                        .last()
                        .unwrap_or(&entry.project_path)
                        .to_string(),
                    total_cost: 0.0,
                    total_tokens: 0,
                    session_count: 0,
                    last_used: entry.timestamp.clone(),
                });
        project_stat.total_cost += entry.cost;
        project_stat.total_tokens += entry.input_tokens
            + entry.output_tokens
            + entry.cache_creation_tokens
            + entry.cache_read_tokens;
        // Session count will be set later from unique session tracking
        if entry.timestamp > project_stat.last_used {
            project_stat.last_used = entry.timestamp.clone();
        }

        // Update API base URL stats
        let api_base_url_stat = api_base_url_stats
            .entry(entry.api_base_url.clone())
            .or_insert(ApiBaseUrlUsage {
                api_base_url: entry.api_base_url.clone(),
                total_cost: 0.0,
                total_tokens: 0,
                input_tokens: 0,
                output_tokens: 0,
                cache_creation_tokens: 0,
                cache_read_tokens: 0,
                session_count: 0,
            });
        api_base_url_stat.total_cost += entry.cost;
        api_base_url_stat.input_tokens += entry.input_tokens;
        api_base_url_stat.output_tokens += entry.output_tokens;
        api_base_url_stat.cache_creation_tokens += entry.cache_creation_tokens;
        api_base_url_stat.cache_read_tokens += entry.cache_read_tokens;
        api_base_url_stat.total_tokens = api_base_url_stat.input_tokens + api_base_url_stat.output_tokens + api_base_url_stat.cache_creation_tokens + api_base_url_stat.cache_read_tokens;
        // Session count will be set later from unique session tracking
    }

    let total_tokens = total_input_tokens
        + total_output_tokens
        + total_cache_creation_tokens
        + total_cache_read_tokens;
    let total_sessions = unique_sessions.len() as u64;

    // Set correct session counts and convert hashmaps to sorted vectors
    let mut by_model: Vec<ModelUsage> = model_stats.into_iter().map(|(model, mut stat)| {
        stat.session_count = model_sessions.get(&model).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_model.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_date: Vec<DailyUsage> = daily_stats.into_values().collect();
    by_date.sort_by(|a, b| b.date.cmp(&a.date));

    let mut by_project: Vec<ProjectUsage> = project_stats.into_iter().map(|(project_path, mut stat)| {
        stat.session_count = project_sessions.get(&project_path).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_project.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    let mut by_api_base_url: Vec<ApiBaseUrlUsage> = api_base_url_stats.into_iter().map(|(api_url, mut stat)| {
        stat.session_count = api_sessions.get(&api_url).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_api_base_url.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    Ok(UsageStats {
        total_cost,
        total_tokens,
        total_input_tokens,
        total_output_tokens,
        total_cache_creation_tokens,
        total_cache_read_tokens,
        total_sessions,
        by_model,
        by_date,
        by_project,
        by_api_base_url,
    })
}

#[command]
pub fn get_session_stats(
    since: Option<String>,
    until: Option<String>,
    order: Option<String>,
) -> Result<Vec<ProjectUsage>, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);

    let since_date = since.and_then(|s| NaiveDate::parse_from_str(&s, "%Y%m%d").ok());
    let until_date = until.and_then(|s| NaiveDate::parse_from_str(&s, "%Y%m%d").ok());

    let filtered_entries: Vec<_> = all_entries
        .into_iter()
        .filter(|e| {
            if let Ok(dt) = DateTime::parse_from_rfc3339(&e.timestamp) {
                let date = dt.date_naive();
                let is_after_since = since_date.map_or(true, |s| date >= s);
                let is_before_until = until_date.map_or(true, |u| date <= u);
                is_after_since && is_before_until
            } else {
                false
            }
        })
        .collect();

    let mut session_stats: HashMap<String, ProjectUsage> = HashMap::new();
    for entry in &filtered_entries {
        let session_key = format!("{}/{}", entry.project_path, entry.session_id);
        let project_stat = session_stats
            .entry(session_key)
            .or_insert_with(|| ProjectUsage {
                project_path: entry.project_path.clone(),
                project_name: entry.session_id.clone(), // Using session_id as project_name for session view
                total_cost: 0.0,
                total_tokens: 0,
                session_count: 0, // In this context, this will count entries per session
                last_used: " ".to_string(),
            });

        project_stat.total_cost += entry.cost;
        project_stat.total_tokens += entry.input_tokens
            + entry.output_tokens
            + entry.cache_creation_tokens
            + entry.cache_read_tokens;
        // Session count will be set later from unique session tracking
        if entry.timestamp > project_stat.last_used {
            project_stat.last_used = entry.timestamp.clone();
        }
    }

    let mut by_session: Vec<ProjectUsage> = session_stats.into_values().collect();

    // Sort by last_used date
    if let Some(order_str) = order {
        if order_str == "asc" {
            by_session.sort_by(|a, b| a.last_used.cmp(&b.last_used));
        } else {
            by_session.sort_by(|a, b| b.last_used.cmp(&a.last_used));
        }
    } else {
        // Default to descending
        by_session.sort_by(|a, b| b.last_used.cmp(&a.last_used));
    }

    Ok(by_session)
}

#[command]
pub fn get_usage_by_api_base_url() -> Result<Vec<ApiBaseUrlUsage>, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);

    if all_entries.is_empty() {
        return Ok(vec![]);
    }

    let mut api_base_url_stats: HashMap<String, ApiBaseUrlUsage> = HashMap::new();
    
    // Track unique sessions for accurate counting
    let mut api_sessions: HashMap<String, HashSet<String>> = HashMap::new();

    for entry in &all_entries {
        // Track sessions per API base URL
        api_sessions
            .entry(entry.api_base_url.clone())
            .or_insert_with(HashSet::new)
            .insert(entry.session_id.clone());
        let api_base_url_stat = api_base_url_stats
            .entry(entry.api_base_url.clone())
            .or_insert(ApiBaseUrlUsage {
                api_base_url: entry.api_base_url.clone(),
                total_cost: 0.0,
                total_tokens: 0,
                input_tokens: 0,
                output_tokens: 0,
                cache_creation_tokens: 0,
                cache_read_tokens: 0,
                session_count: 0,
            });

        api_base_url_stat.total_cost += entry.cost;
        api_base_url_stat.input_tokens += entry.input_tokens;
        api_base_url_stat.output_tokens += entry.output_tokens;
        api_base_url_stat.cache_creation_tokens += entry.cache_creation_tokens;
        api_base_url_stat.cache_read_tokens += entry.cache_read_tokens;
        api_base_url_stat.total_tokens = api_base_url_stat.input_tokens + api_base_url_stat.output_tokens + api_base_url_stat.cache_creation_tokens + api_base_url_stat.cache_read_tokens;
        // Session count will be set later from unique session tracking
    }

    let mut by_api_base_url: Vec<ApiBaseUrlUsage> = api_base_url_stats.into_iter().map(|(api_url, mut stat)| {
        stat.session_count = api_sessions.get(&api_url).map(|s| s.len()).unwrap_or(0) as u64;
        stat
    }).collect();
    by_api_base_url.sort_by(|a, b| b.total_cost.partial_cmp(&a.total_cost).unwrap());

    Ok(by_api_base_url)
}

#[derive(Debug, Serialize)]
pub struct ActiveSessionInfo {
    session_id: String,
    project_path: String,
    start_time: String,
    last_activity: String,
    total_tokens: u64,
    total_cost: f64,
    time_remaining_hours: f64,
    is_active: bool,
}

#[command]
pub fn get_active_sessions() -> Result<Vec<ActiveSessionInfo>, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);
    if all_entries.is_empty() {
        return Ok(vec![]);
    }

    let session_starts = track_active_sessions(&all_entries);
    let current_time = Local::now();
    
    // Group entries by session
    let mut session_data: HashMap<String, (u64, f64, String, String)> = HashMap::new();
    
    for entry in &all_entries {
        let session_stats = session_data
            .entry(entry.session_id.clone())
            .or_insert((0, 0.0, entry.project_path.clone(), entry.timestamp.clone()));
            
        session_stats.0 += entry.input_tokens + entry.output_tokens + entry.cache_creation_tokens + entry.cache_read_tokens;
        session_stats.1 += entry.cost;
        
        // Update last activity if this entry is more recent
        if entry.timestamp > session_stats.3 {
            session_stats.3 = entry.timestamp.clone();
        }
    }
    
    let mut active_sessions = Vec::new();
    
    for (session_id, (total_tokens, total_cost, project_path, last_activity)) in session_data {
        if let Some(start_time) = session_starts.get(&session_id) {
            let elapsed_hours = current_time.signed_duration_since(*start_time).num_hours() as f64;
            let time_remaining = (SESSION_WINDOW_HOURS as f64) - elapsed_hours;
            let is_active = time_remaining > 0.0;
            
            active_sessions.push(ActiveSessionInfo {
                session_id,
                project_path,
                start_time: start_time.to_rfc3339(),
                last_activity,
                total_tokens,
                total_cost,
                time_remaining_hours: time_remaining.max(0.0),
                is_active,
            });
        }
    }
    
    // Sort by remaining time (active sessions first, then by time remaining)
    active_sessions.sort_by(|a, b| {
        match (a.is_active, b.is_active) {
            (true, false) => std::cmp::Ordering::Less,
            (false, true) => std::cmp::Ordering::Greater,
            _ => b.time_remaining_hours.partial_cmp(&a.time_remaining_hours).unwrap(),
        }
    });
    
    Ok(active_sessions)
}

#[derive(Debug, Serialize)]
pub struct BurnRateInfo {
    current_burn_rate: f64,  // tokens per minute
    estimated_depletion_time: Option<String>,  // when tokens will run out
    session_utilization: f64,  // percentage of session time used
    recommendations: Vec<String>,
}

#[command]
pub fn get_burn_rate_analysis() -> Result<BurnRateInfo, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);
    if all_entries.is_empty() {
        return Ok(BurnRateInfo {
            current_burn_rate: 0.0,
            estimated_depletion_time: None,
            session_utilization: 0.0,
            recommendations: vec!["No usage data available".to_string()],
        });
    }

    let current_time = Local::now();
    let one_hour_ago = current_time - Duration::hours(1);
    
    // Filter entries from the last hour for burn rate calculation
    let recent_entries: Vec<_> = all_entries
        .iter()
        .filter(|entry| {
            if let Ok(entry_time) = DateTime::parse_from_rfc3339(&entry.timestamp) {
                entry_time.with_timezone(&Local) > one_hour_ago
            } else {
                false
            }
        })
        .collect();
    
    if recent_entries.is_empty() {
        return Ok(BurnRateInfo {
            current_burn_rate: 0.0,
            estimated_depletion_time: None,
            session_utilization: 0.0,
            recommendations: vec!["No recent activity detected".to_string()],
        });
    }
    
    // Calculate burn rate (tokens per minute)
    let total_recent_tokens: u64 = recent_entries
        .iter()
        .map(|entry| entry.input_tokens + entry.output_tokens + entry.cache_creation_tokens + entry.cache_read_tokens)
        .sum();
    
    let burn_rate = total_recent_tokens as f64 / 60.0; // per minute
    
    // Find active sessions and estimate when they'll run out
    let session_starts = track_active_sessions(&all_entries);
    let active_sessions = session_starts
        .iter()
        .filter(|(_, start_time)| {
            current_time.signed_duration_since(**start_time).num_hours() < SESSION_WINDOW_HOURS
        })
        .count();
    
    // Calculate session utilization
    let session_utilization = if !session_starts.is_empty() {
        let avg_session_age: f64 = session_starts
            .values()
            .map(|start| current_time.signed_duration_since(*start).num_hours() as f64)
            .sum::<f64>() / session_starts.len() as f64;
        
        (avg_session_age / SESSION_WINDOW_HOURS as f64 * 100.0).min(100.0)
    } else {
        0.0
    };
    
    // Generate recommendations
    let mut recommendations = Vec::new();
    
    if burn_rate > 100.0 {
        recommendations.push("High burn rate detected. Consider optimizing prompts or using smaller models.".to_string());
    }
    
    if session_utilization > 80.0 {
        recommendations.push("Sessions are nearing expiration. Plan token-intensive tasks around session resets.".to_string());
    }
    
    if active_sessions > 3 {
        recommendations.push("Multiple active sessions detected. Consider consolidating work into fewer sessions.".to_string());
    }
    
    if recommendations.is_empty() {
        recommendations.push("Usage patterns look optimal.".to_string());
    }
    
    Ok(BurnRateInfo {
        current_burn_rate: burn_rate,
        estimated_depletion_time: None, // TODO: Implement based on current session limits
        session_utilization,
        recommendations,
    })
}

/// New command to get cache tokens for a specific session
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SessionCacheTokens {
    pub session_id: String,
    pub total_cache_creation_tokens: u64,
    pub total_cache_read_tokens: u64,
}

#[command]
pub fn get_session_cache_tokens(session_id: String) -> Result<SessionCacheTokens, String> {
    let claude_path = dirs::home_dir()
        .ok_or("Failed to get home directory")?
        .join(".claude");

    let all_entries = get_all_usage_entries(&claude_path);

    // Filter entries for this specific session
    let session_entries: Vec<_> = all_entries
        .into_iter()
        .filter(|entry| entry.session_id == session_id)
        .collect();

    // Sum up cache tokens for this session
    let mut total_cache_creation_tokens = 0u64;
    let mut total_cache_read_tokens = 0u64;

    for entry in session_entries {
        total_cache_creation_tokens += entry.cache_creation_tokens;
        total_cache_read_tokens += entry.cache_read_tokens;
    }

    Ok(SessionCacheTokens {
        session_id,
        total_cache_creation_tokens,
        total_cache_read_tokens,
    })
}

/// Get real-time usage data from database
#[command]
pub async fn get_realtime_usage_stats(app: AppHandle) -> Result<Vec<UsageEntry>, String> {
    use crate::commands::agents::AgentDb;

    // Get the database from app state
    let agent_db = app.state::<AgentDb>();
    let conn = agent_db.0.lock().map_err(|e| e.to_string())?;

    // Query recent usage entries from database
    let mut stmt = conn
        .prepare(
            "SELECT session_id, timestamp, model, input_tokens, output_tokens,
                    cache_creation_tokens, cache_read_tokens, cost, project_path, created_at
             FROM usage_entries
             ORDER BY created_at DESC
             LIMIT 1000"
        )
        .map_err(|e| e.to_string())?;

    let usage_entries = stmt
        .query_map([], |row| {
            Ok(UsageEntry {
                session_id: row.get(0)?,
                timestamp: row.get(1)?,
                model: row.get(2)?,
                input_tokens: row.get::<_, i64>(3)? as u64,
                output_tokens: row.get::<_, i64>(4)? as u64,
                cache_creation_tokens: row.get::<_, i64>(5)? as u64,
                cache_read_tokens: row.get::<_, i64>(6)? as u64,
                cost: row.get(7)?,
                project_path: row.get(8)?,
                api_base_url: "https://api.anthropic.com".to_string(), // Default API base URL
            })
        })
        .map_err(|e| e.to_string())?
        .collect::<Result<Vec<_>, _>>()
        .map_err(|e| e.to_string())?;

    Ok(usage_entries)
}
